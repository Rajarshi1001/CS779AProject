{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ee3f94f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.spatial.distance import cosine\n",
    "from sentence_transformers import SentenceTransformer, SentencesDataset, LoggingHandler, util\n",
    "from sentence_transformers import models, losses\n",
    "from sentence_transformers.readers import STSDataReader\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da1f7ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>SourceID</th>\n",
       "      <th>SubsetID</th>\n",
       "      <th>PairID</th>\n",
       "      <th>Score</th>\n",
       "      <th>Sentence_1</th>\n",
       "      <th>Sentence_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Formality</td>\n",
       "      <td>Formality_pp</td>\n",
       "      <td>Formality_pp_222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>It that happens, just pull the plug.</td>\n",
       "      <td>if that ever happens, just pull the plug.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>STS</td>\n",
       "      <td>STS</td>\n",
       "      <td>STS_237</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A black dog running through water.</td>\n",
       "      <td>A black dog is running through some water.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ParaNMT</td>\n",
       "      <td>ParaNMT_pp</td>\n",
       "      <td>ParaNMT_pp_204</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I've been searchingthe entire abbey for you.</td>\n",
       "      <td>I'm looking for you all over the abbey.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Formality</td>\n",
       "      <td>Formality_pp</td>\n",
       "      <td>Formality_pp_119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>If he is good looking and has a good personali...</td>\n",
       "      <td>If he's good looking, and a good personality, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Formality</td>\n",
       "      <td>Formality_pp</td>\n",
       "      <td>Formality_pp_174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>She does not hate you, she is just annoyed wit...</td>\n",
       "      <td>She doesn't hate you, she is just annoyed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>STS</td>\n",
       "      <td>STS</td>\n",
       "      <td>STS_211</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Actor Gazzara dead at 81</td>\n",
       "      <td>Actor Ben Gazzara dies at 81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Formality</td>\n",
       "      <td>Formality_pp</td>\n",
       "      <td>Formality_pp_277</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No, I really didn't want New York to win.</td>\n",
       "      <td>No i didn't want New york to win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Formality</td>\n",
       "      <td>Formality_pp</td>\n",
       "      <td>Formality_pp_167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I hae no problems with them.</td>\n",
       "      <td>lol i have no problems with them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Formality</td>\n",
       "      <td>Formality_pp</td>\n",
       "      <td>Formality_pp_123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Your parents do not have to like your boyfrien...</td>\n",
       "      <td>your parents dont have to like your bf, you do.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Formality</td>\n",
       "      <td>Formality_pp</td>\n",
       "      <td>Formality_pp_194</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I think Taylor is really cute, but I hate his ...</td>\n",
       "      <td>I think Taylor is SUPER cute...but I hate his ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index   SourceID      SubsetID            PairID  Score   \n",
       "0      0  Formality  Formality_pp  Formality_pp_222    1.0  \\\n",
       "1      1        STS           STS           STS_237    1.0   \n",
       "2      2    ParaNMT    ParaNMT_pp    ParaNMT_pp_204    1.0   \n",
       "3      3  Formality  Formality_pp  Formality_pp_119    1.0   \n",
       "4      4  Formality  Formality_pp  Formality_pp_174    1.0   \n",
       "5      5        STS           STS           STS_211    1.0   \n",
       "6      6  Formality  Formality_pp  Formality_pp_277    1.0   \n",
       "7      7  Formality  Formality_pp  Formality_pp_167    1.0   \n",
       "8      8  Formality  Formality_pp  Formality_pp_123    1.0   \n",
       "9      9  Formality  Formality_pp  Formality_pp_194    1.0   \n",
       "\n",
       "                                          Sentence_1   \n",
       "0               It that happens, just pull the plug.  \\\n",
       "1                 A black dog running through water.   \n",
       "2       I've been searchingthe entire abbey for you.   \n",
       "3  If he is good looking and has a good personali...   \n",
       "4  She does not hate you, she is just annoyed wit...   \n",
       "5                           Actor Gazzara dead at 81   \n",
       "6          No, I really didn't want New York to win.   \n",
       "7                       I hae no problems with them.   \n",
       "8  Your parents do not have to like your boyfrien...   \n",
       "9  I think Taylor is really cute, but I hate his ...   \n",
       "\n",
       "                                          Sentence_2  \n",
       "0          if that ever happens, just pull the plug.  \n",
       "1         A black dog is running through some water.  \n",
       "2            I'm looking for you all over the abbey.  \n",
       "3  If he's good looking, and a good personality, ...  \n",
       "4         She doesn't hate you, she is just annoyed.  \n",
       "5                       Actor Ben Gazzara dies at 81  \n",
       "6                   No i didn't want New york to win  \n",
       "7                  lol i have no problems with them.  \n",
       "8    your parents dont have to like your bf, you do.  \n",
       "9  I think Taylor is SUPER cute...but I hate his ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"Semantic_Relatedness_SemEval2024/Pilot_data\"\n",
    "pilotdata = pd.read_csv(\"data.csv\")\n",
    "pilotdata[[\"Sentence_1\", \"Sentence_2\"]] = pilotdata[\"Text\"].str.split(\"\\n\", expand = True)\n",
    "pilotdata.drop([\"Text\"], inplace = True, axis = 1)\n",
    "print(len(pilotdata))\n",
    "pilotdata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c31f834b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4951\n",
      "275\n",
      "276\n"
     ]
    }
   ],
   "source": [
    "train_file = \"str_train.csv\"\n",
    "test_file = \"str_test.csv\"\n",
    "val_file = \"str_val.csv\"\n",
    "DATA_DIR = \"STR_dataset\"\n",
    "train_size = int(len(pilotdata)*0.9)\n",
    "val_size = int(len(pilotdata)*0.05)\n",
    "test_size = len(pilotdata) - train_size - val_size\n",
    "train_data = pilotdata.loc[:train_size]\n",
    "test_data = pilotdata.loc[train_size + val_size:]\n",
    "val_data = pilotdata.loc[train_size:train_size + val_size]\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(len(val_data))\n",
    "\n",
    "if os.path.exists(os.path.join(DATA_DIR,\"str_train.csv\")) and os.path.exists(os.path.join(DATA_DIR,\"str_val.csv\")) and os.path.exists(os.path.join(DATA_DIR,\"str_test.csv\")):\n",
    "    os.remove(os.path.join(DATA_DIR,\"str_train.csv\"))\n",
    "    os.remove(os.path.join(DATA_DIR,\"str_val.csv\"))\n",
    "    os.remove(os.path.join(DATA_DIR,\"str_test.csv\"))\n",
    "\n",
    "# preparing the dataset\n",
    "for idx, row in train_data.iterrows():\n",
    "    with open(os.path.join(DATA_DIR,train_file), \"a\") as file:\n",
    "        line = row[\"Sentence_1\"] + \"\\t\" + row[\"Sentence_2\"] + \"\\t\" + str(row[\"Score\"])\n",
    "        file.write(line+\"\\n\")\n",
    "for idx, row in test_data.iterrows():\n",
    "    with open(os.path.join(DATA_DIR,test_file), \"a\") as file:\n",
    "        line = row[\"Sentence_1\"] + \"\\t\" + row[\"Sentence_2\"] + \"\\t\" + str(row[\"Score\"])\n",
    "        file.write(line+\"\\n\")  \n",
    "for idx, row in val_data.iterrows():\n",
    "    with open(os.path.join(DATA_DIR,val_file), \"a\") as file:\n",
    "        line = row[\"Sentence_1\"] + \"\\t\" + row[\"Sentence_2\"] + \"\\t\" + str(row[\"Score\"])\n",
    "        file.write(line+\"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3bf10c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Splitting the batch of InputExample objects into separate lists\n",
    "    sentences1 = [example.texts[0] for example in batch]\n",
    "    sentences2 = [example.texts[1] for example in batch]\n",
    "    scores = [example.label for example in batch]\n",
    "    return sentences1, sentences2, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9daf8071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9dad171cdc4335936d9f32aeb95a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af5c7044ef040b4823ff8a8ccc7a613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/310 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f33c9ee3202471c8b6828a803fdc1ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/310 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8a79f1f9a74e87ae46aa7a83c34d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/310 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc27f906196848c58e048e8b7ce8ddec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/310 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_batch_size = 16\n",
    "model = SentenceTransformer(\"distiluse-base-multilingual-cased-v1\")\n",
    "str_reader = STSDataReader('STR_dataset', normalize_scores=True)\n",
    "traindataset = SentencesDataset(examples = str_reader.get_examples(train_file), model = model)\n",
    "trainloader = DataLoader(traindataset, batch_size=train_batch_size,collate_fn=collate_fn,shuffle=True)\n",
    "train_loss = losses.CosineSimilarityLoss(model = model)\n",
    "valdataset = SentencesDataset(examples = str_reader.get_examples(val_file), model = model)\n",
    "valloader = DataLoader(valdataset, batch_size=train_batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "sentences1 = []\n",
    "sentences2 = []\n",
    "scores = []\n",
    "\n",
    "for batch in valloader:\n",
    "#     print(batch)\n",
    "    batch_sentences1, batch_sentences2, batch_scores = batch\n",
    "    sentences1.extend(batch_sentences1)\n",
    "    sentences2.extend(batch_sentences2)\n",
    "    scores.extend(batch_scores)\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator(sentences1, sentences2, scores)\n",
    "\n",
    "num_epochs = 4\n",
    "model.fit(train_objectives=[(trainloader, train_loss)],\n",
    "         evaluator = evaluator,\n",
    "         epochs = num_epochs,\n",
    "         evaluation_steps= 10000,\n",
    "         warmup_steps = 100,\n",
    "         output_path=\"model_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23c1e600",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('STR_dataset/str_train.csv', 'r') as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        try:\n",
    "            float(parts[0])\n",
    "        except ValueError:\n",
    "            print(f\"Error on line {idx + 1}: {line.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "53e0d389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009082291259355819"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdataset = SentencesDataset(examples=str_reader.get_examples('str_test.csv'), model=model)\n",
    "testloader = DataLoader(testdataset, shuffle=False, batch_size=train_batch_size, collate_fn=collate_fn)\n",
    "\n",
    "sentences1 = []\n",
    "sentences2 = []\n",
    "scores = []\n",
    "\n",
    "for batch in testloader:\n",
    "    batch_sentences1, batch_sentences2, batch_scores = batch\n",
    "    sentences1.extend(batch_sentences1)\n",
    "    sentences2.extend(batch_sentences2)\n",
    "    scores.extend(batch_scores)\n",
    "\n",
    "test_evaluator = EmbeddingSimilarityEvaluator(sentences1, sentences2, scores)\n",
    "\n",
    "model.evaluate(test_evaluator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9217a6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.476022332906723\n"
     ]
    }
   ],
   "source": [
    "model_path = 'model_path'\n",
    "# model = SentenceTransformer(\"distiluse-base-multilingual-cased-v1\")\n",
    "model = SentenceTransformer(model_path)\n",
    "sentence1 = \"It that happens, just pull the plug.\"\n",
    "sentence2 = \"if that just happens, just pull the plug.\"\n",
    "\n",
    "embedding1 = model.encode(sentence1)\n",
    "embedding2 = model.encode(sentence2)\n",
    "\n",
    "similarity = 1 - cosine(embedding1, embedding2)  \n",
    "print(\"Similarity:\", similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
